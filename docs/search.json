[
  {
    "objectID": "nlp.html",
    "href": "nlp.html",
    "title": "Crosstech Solutions Group",
    "section": "",
    "text": "В данном разделе представлены результаты комплексного анализа текстов статей, включающего аннотирование, частотный анализ, расчёт TF-IDF, анализ распределения слов с помощью диаграммы Ципфа, сентимент-анализ и построение эмбеддингов.\nНу, обо все по порядку)"
  },
  {
    "objectID": "nlp.html#введение",
    "href": "nlp.html#введение",
    "title": "Crosstech Solutions Group",
    "section": "",
    "text": "В данном разделе представлены результаты комплексного анализа текстов статей, включающего аннотирование, частотный анализ, расчёт TF-IDF, анализ распределения слов с помощью диаграммы Ципфа, сентимент-анализ и построение эмбеддингов.\nНу, обо все по порядку)"
  },
  {
    "objectID": "nlp.html#токенизация-и-лемматизация",
    "href": "nlp.html#токенизация-и-лемматизация",
    "title": "Crosstech Solutions Group",
    "section": "Токенизация и лемматизация",
    "text": "Токенизация и лемматизация\nКак обычно подгружаю все необходимые пакеты.\n\nlibrary(tidyverse) \nlibrary(tidytext)\nlibrary(udpipe)\nlibrary(stopwords)\nlibrary(wordcloud)\nlibrary(RColorBrewer)\nlibrary(extrafont)\nlibrary(widyr)\n\nТеперь загружаю широко известную UdPipe-модель SynTagRus для аннотирования текстов самых популярных статей. Это позволит сделать мне выводы о том, какие темы вызывали у аудитории наиболее бурный интерес.\n\nrussian_model &lt;- udpipe_load_model(file = \"russian-syntagrus-ud-2.5-191206.udpipe\")\n\nВ чанке ниже я аннотирую тексты статей и перевожу результат в тиббл.\n\nctsg_articles_annotate &lt;- udpipe_annotate(russian_model, result$text, doc_id = result$hit_id)\n\nctsg_articles_pos &lt;- ctsg_articles_annotate |&gt; \n  as_tibble()\n\nПолучается примерно такая таблица (при визуализации таблицы я убрала столбец sentence, чтобы выглядело опрятнее на странице). Полный вариант тиббла можно забрать ДОБАВИТЬ ССЫЛКУ_здесь.\n\n\n\n\n\n\n\n\ndoc_id\nparagraph_id\nsentence_id\ntoken_id\ntoken\nlemma\nupos\nxpos\nfeats\nhead_token_id\ndep_rel\ndeps\nmisc\n\n\n\n\n1\n1\n1\n1\nВ\nв\nADP\nNA\nNA\n3\ncase\nNA\nNA\n\n\n1\n1\n1\n2\nпоследние\nпоследний\nADJ\nNA\nAnimacy=Inan|Case=Acc|Degree=Pos|Number=Plur\n3\namod\nNA\nNA\n\n\n1\n1\n1\n3\nгоды\nгод\nNOUN\nNA\nAnimacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n4\nobl\nNA\nNA\n\n\n1\n1\n1\n4\nпоявляется\nпоявляться\nVERB\nNA\nAspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n0\nroot\nNA\nNA\n\n\n1\n1\n1\n5\nвсё\nвсе\nPART\nNA\nNA\n6\nadvmod\nNA\nNA\n\n\n1\n1\n1\n6\nбольше\nбольше\nNUM\nNA\nNA\n7\nnummod\nNA\nNA\n\n\n1\n1\n1\n7\nтехнологий\nтехнология\nNOUN\nNA\nAnimacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n4\nnsubj\nNA\nNA\n\n\n1\n1\n1\n8\nс\nс\nADP\nNA\nNA\n9\ncase\nNA\nNA\n\n\n1\n1\n1\n9\nиспользованием\nиспользование\nNOUN\nNA\nAnimacy=Inan|Case=Ins|Gender=Neut|Number=Sing\n7\nnmod\nNA\nNA\n\n\n1\n1\n1\n10\nComputer\nComputer\nPROPN\nNA\nForeign=Yes\n9\nflat:foreign\nNA\nNA\n\n\n\n\n\n\n\nСоздам еще один тиббл, в котором будут храниться все токены без стоп-слов.\n\nsw &lt;- stopwords(language = \"ru\", source = \"stopwords-iso\")\n\nresult_words_tidy &lt;- ctsg_articles_pos  |&gt;  \n  filter(!lemma %in% sw)\n\n\n\n\n\n\n\n\n\ndoc_id\nparagraph_id\nsentence_id\ntoken_id\ntoken\nlemma\nupos\nxpos\nfeats\nhead_token_id\ndep_rel\ndeps\nmisc\n\n\n\n\n1\n1\n1\n4\nпоявляется\nпоявляться\nVERB\nNA\nAspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n0\nroot\nNA\nNA\n\n\n1\n1\n1\n7\nтехнологий\nтехнология\nNOUN\nNA\nAnimacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n4\nnsubj\nNA\nNA\n\n\n1\n1\n1\n9\nиспользованием\nиспользование\nNOUN\nNA\nAnimacy=Inan|Case=Ins|Gender=Neut|Number=Sing\n7\nnmod\nNA\nNA\n\n\n1\n1\n1\n10\nComputer\nComputer\nPROPN\nNA\nForeign=Yes\n9\nflat:foreign\nNA\nNA\n\n\n1\n1\n1\n11\nVision\nVision\nPROPN\nNA\nForeign=Yes\n9\nflat:foreign\nNA\nSpaceAfter=No\n\n\n1\n1\n1\n12\n:\n:\nPUNCT\nNA\nNA\n4\npunct\nNA\nNA\n\n\n1\n1\n1\n15\nбеспилотные\nбеспилотный\nADJ\nNA\nCase=Nom|Degree=Pos|Number=Plur\n16\namod\nNA\nNA\n\n\n1\n1\n1\n16\nавтомобили\nавтомобиль\nNOUN\nNA\nAnimacy=Inan|Case=Nom|Gender=Masc|Number=Plur\n4\nparataxis\nNA\nSpaceAfter=No\n\n\n1\n1\n1\n17\n,\n,\nPUNCT\nNA\nNA\n19\npunct\nNA\nNA\n\n\n1\n1\n1\n19\nFace\nFace\nPROPN\nNA\nForeign=Yes\n16\nconj\nNA\nNA\n\n\n\n\n\n\n\nТут учитываются знаки препинания, но их легко можно будет убрать далее.\nДалее я решила построить облако слов из существительных. Мы видим, что наиболее чатыми словами являются, связанные с трудоустройством.\n\nset.seed(123)\nnouns &lt;- result_words_tidy  |&gt; \n  filter(upos %in% c(\"NOUN\")) |&gt; \n  count(lemma) |&gt; \n  arrange(-n) \n\npal &lt;- RColorBrewer::brewer.pal(9, \"Blues\")[4:10] \nwordcloud(nouns$lemma, nouns$n, colors = pal, max.words = 30)\n\n\n\n\n\n\n\n\nЗатем я считаю абсолютную частотность слов в самых популярных статьях. Здесь как раз-таки я убираю знаки препинания, которые создали бы некоторый шум.\n\nfreq_counts &lt;- result_words_tidy |&gt; \n  filter(upos != \"PUNCT\") |&gt; \n  count(lemma, doc_id, sort = TRUE) |&gt; \n  rename(count = n)\n\n#Абсолютная частотность\nfreq_counts |&gt; \n  group_by(doc_id) |&gt; \n  slice_head(n = 10) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(reorder_within(lemma, count, doc_id), count, fill = as.factor(doc_id))) +\n  geom_col(show.legend = F) + \n  scale_fill_manual(values = pal) +\n  scale_x_reordered() +\n  facet_wrap(~doc_id, nrow = 2, scales = \"free\") +\n  coord_flip()  +\n  theme_light() +\n  theme(text = element_text(size = 12, family = \"Montserrat Medium\"),\n        strip.background = element_rect(fill = \"#D0CECE\"),\n        strip.text = element_text(color = \"black\")) +\n xlab(NULL) +\n  ylab(NULL)\n\n\n\n\n\n\n\n\nМы видим, что тематически статьи с номерами 2, 3 и 4 будто бы очень близки. Может показаться, что это преждевременные выводы, но забегая вперед скажу, что, действительно, в некоторых статьях всего пула статей выделяется топик об особенностях найма сотрудников в компанию. Неудивительно, потому что эта тема по-прежнему очень актуальна, хоть сейчас и нет такого бума вката в ИТ и рынок труда в целом очень изменился.\nНо ограничиваться абсолютной частотностью не нужно. Тем более нужно учитывать, что статьи имеют разную длину (минимальная длина текста популярной статьи содержит 1851 слов, а максимальная — 3348). Поэтому смотрим относительную частотность tf-idf.\n\ntokens_tf &lt;- ctsg_articles_pos |&gt; \n  mutate(total = nrow(ctsg_articles_pos)) |&gt; \n  add_count(lemma, sort = TRUE) |&gt; \n  distinct(doc_id, lemma, total, n) |&gt; \n  mutate(tf = n / total) |&gt; \n  arrange(tf)\n\nКак всегда представляю только небольшой фрагмент тиббла. Полную таблицу можно забрать по ВСТАВИТЬссылке.\n\n\n\n\n\n\n\n\ndoc_id\nlemma\ntotal\nn\ntf\n\n\n\n\n1\nпоявляться\n15364\n1\n6.508722e-05\n\n\n1\nComputer\n15364\n1\n6.508722e-05\n\n\n1\nVision\n15364\n1\n6.508722e-05\n\n\n1\nбеспилотный\n15364\n1\n6.508722e-05\n\n\n1\nавтомобиль\n15364\n1\n6.508722e-05\n\n\n1\nтелефон\n15364\n1\n6.508722e-05\n\n\n1\nкамера\n15364\n1\n6.508722e-05\n\n\n1\nспособный\n15364\n1\n6.508722e-05\n\n\n1\nутечка\n15364\n1\n6.508722e-05\n\n\n1\nтеплоизоляция\n15364\n1\n6.508722e-05\n\n\n\n\n\n\n\nПо полученным данным можно построить гистограмму. Она доказывает распределение слов естественных языков по Закону Ципфа.1\n\ntokens_tf |&gt; \n  ggplot(aes(tf)) +\n  geom_histogram(show.legend = FALSE, \n                 fill = \"aliceblue\", \n                 color = \"grey\",\n                 bins = 50) +\n  theme_light()\n\n\n\n\n\n\n\n\nВношу последние штрихи и визуализирую результат.\n\nctsg_tfidf &lt;- tokens_tf |&gt; \n  bind_tf_idf(lemma, doc_id, n)\n\n#наиболее характерные для документов токены\nctsg_tfidf |&gt; \n  arrange(-tf_idf) |&gt; \n  group_by(doc_id) |&gt; \n  slice_head(n = 10) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(reorder_within(lemma, tf_idf, doc_id), tf_idf, fill = as.factor(doc_id))) +\n  geom_col(show.legend = F) +\n  labs(x = NULL, y = \"tf-idf\") +\n  facet_wrap(~doc_id, scales = \"free\", nrow = 2) +\n  scale_x_reordered() +\n  scale_fill_manual(values = pal) +\n  coord_flip() +\n  theme_light() +\n  theme(text = element_text(size = 12, family = \"Montserrat Medium\"),\n        strip.background = element_rect(fill = \"#D0CECE\"),\n        strip.text = element_text(color = \"black\"))\n\n\n\n\n\n\n\n\nДа, здесь мы видим немного другие слова, однако они семантически очень близки с теми, что показал нам анализ абсолютных частот. Так, мы можем сделать вывод о том, что среди популярных статей мы можем выделить 2 кластера статей:\n\nкластер статей о трудоустройстве и софт-скиллах в целом;\nкластер технических статей, в которых описываются технологии (причем применяемые/разрабатываемые компанией).\n\nПричем в статье №1 можно сделать вывод о том, что речь идет о машинном обучении для задачи распознавания, а статья №5 описывает контейнерные технологии. Неудивительно, что статьи с такой тематикой вошли в ТОП статей компании. Машинное обучение по-прежнему является востребованным топиком в технарском кругу. Контейнерные технологии также не сбавляет свои обороты в популярности среди технарей.2\nВот так небольшой анализ частот позволил сделать выводы о содержании статей. Затем это можно расширить и применить для всего пула статей."
  },
  {
    "objectID": "nlp.html#сентимент-анализ",
    "href": "nlp.html#сентимент-анализ",
    "title": "Crosstech Solutions Group",
    "section": "Сентимент-анализ",
    "text": "Сентимент-анализ\nВ этом подразделе я рассмотрю анализ эмоционального окраса статей компании на Хабре. Мне кажется, это интересная тема, потому что (по моему сложившемуся мнению) в основном сентимент-анализ применяют для художественной литературы.\nИнтересно будет узнать, пишут ли технари сухим безэмоциональным языком, или же в некоторых текстах прослеживаются положительные или отрицательные коннотации. Давайте узнаем и потом проанализируем полученные результаты :)\nДля начала подготовлю Python-окружение для работы с моделью BERT.\n\nuse_python(\"C:/Users/nazarovskaya.v/AppData/Local/Programs/Python/Python313\")\npy_config()\npy_eval(\"1+1\")\npy_module_available(\"transformers\")\npy_module_available(\"torch\")\ntransformers &lt;- import(\"transformers\")\n\nsentiment_pipeline &lt;- transformers$pipeline(\n  \"sentiment-analysis\", \n  model=\"seara/rubert-tiny2-russian-sentiment\"\n)\n\nЗатем применю пайплайн для анализа текстов. Здесь я заменила параметр max_length, чтобы он адекватно мог анализировать предложенные статьи.\n\narticles_tbl &lt;- tibble(text = articles_ctsg_full$text)\n\nresults_SA &lt;- sentiment_pipeline(\n  as.list(articles_tbl$text),\n  truncation = TRUE,\n  max_length = as.integer(512)\n)\n\nresults_tbl &lt;- tibble(\n  label = map_chr(results_SA, function(x) x$label),\n  score = map_dbl(results_SA, function(x) x$score)\n)\n\nresults_tbl &lt;- results_tbl |&gt; \n  mutate(id = row_number()) |&gt; \n  mutate(id = as.integer(id)) |&gt; \n  inner_join(articles_ctsg_full, by = \"id\") |&gt; \n  select(id, title, label, score)\n\nИ визуализирую полученную таблицу.\n\nresults_tbl |&gt; \n  mutate(index = row_number()) |&gt; \n  mutate(score = case_when(label == \"negative\" ~ score * -1,\n                           .default = score)) |&gt; \n  ggplot(aes(index, score, fill = label)) +\n  geom_col(show.legend = T) + \n  scale_x_continuous(breaks = seq(1, 13, 1)) + \n  labs(title = \"Эмоциональная тональность (BERT)\",\n       x = \"ID статьи\",\n       y = NULL) +\n  theme_light() + \n  theme(axis.title = element_text(size = 14, family = \"Montserrat Medium\"), \n        title = element_text(size = 14, family = \"Montserrat Medium\"),\n        axis.text = element_text(size = 14, family = \"Montserrat Medium\")) + \n  scale_fill_manual(name = \"Окрас\", values = c(pal[1], pal[5]))\n\n\n\n\n\n\n\n\nРезультаты показали, что по мнению BERT среди статей компаний есть две, которые имеют положительный окрас. Оказалось, что это 2 следующие статьи:\n\n\n\n\n\n\n\n\n\nid\ntitle\ntext\nlength\nlink\ncomplexity_label\ndate\nyear\nmonth\nwday\nhour\ntime\nread_time_min\nreach_value\nunique_readers\nvotes\nmark\nnum_of_comments\ntags\nhubs\n\n\n\n\n4\nОт идеи до первого выпуска: как и зачем мы запустили подкаст про ИБ?\nПривет! Это Яна Ильина, HRBP CrossTech Solutions Group, …\n1172\nhttps://habr.com/ru/...\nNA\n2025-02-13\n2025\nFeb\nThu\n14\n14H 29M 0S\n6\n703\n703\n6\n9\n2\nподкаст, бренд, выпуски, …\nБлог компании Crosstech …\n\n\n7\nКак организовать внутренний митап, чтобы он зашел команде? Наши принципы и немного истории\nВсем привет! Меня зовут Ульяна Петракова, я специалист …\n367\nhttps://habr.com/ru/...\nNA\n2024-07-25\n2024\nJul\nThu\n16\n16H 8M 0S\n2\n743\n743\n4\n8\n1\nit-компании, карьера в …\nБлог компании Crosstech …\n\n\n\n\n\n\n\n\nИтак, оставляю ссылки на эти статьи:\n\nОт идеи до первого выпуска: как и зачем мы запустили подкаст про ИБ?3\nКак организовать внутренний митап, чтобы он зашел команде? Наши принципы и немного истории4.\n\nОбе эти статьи затрагивают HR-бренд, где ОЧЕНЬ важен позитивный окрас текста. Поэтому я думаю, BERT здесь не ошибся."
  },
  {
    "objectID": "nlp.html#эмбеддинги",
    "href": "nlp.html#эмбеддинги",
    "title": "Crosstech Solutions Group",
    "section": "Эмбеддинги",
    "text": "Эмбеддинги\nНу и последнее, что я рассмотрю в этом проекте, это векторное представление слов. Я не буду здесь писать много, потому что на часах 2:08 и хочется спать. Ну чтош, приступим!\nСейчас я аннотирую тексты всех статей компании.\n\nctsg_articles_annotate_all &lt;- udpipe_annotate(russian_model, articles_ctsg_full$text, doc_id = articles_ctsg_full$id)\n\n\nctsg_articles_pos &lt;- ctsg_articles_annotate |&gt; \n  as_tibble()\n\nДелаю контекстные окна.\n\nslide_windows &lt;- function(tbl, window_size) {\n skipgrams &lt;- slider::slide(\n   tbl,\n    ~.x,\n    .after = window_size - 1,\n    .step = 1,\n    .complete = TRUE\n  )\n\n  safe_mutate &lt;- safely(mutate)\n\n  out &lt;- map2(skipgrams,\n              1:length(skipgrams),\n              ~ safe_mutate(.x, window_id = .y))\n\n  out  |&gt;\n    transpose()  |&gt;\n    pluck(\"result\")  |&gt;\n    compact()  |&gt;\n    bind_rows()\n}\n\nЗатем убираю ненужное и применяю функцию. Затем здесь же высчитываю PMI и PPMI.\n\nsw &lt;- stopwords(language = \"ru\", source = \"stopwords-iso\")\n\narticles_tokens_pruned &lt;- ctsg_articles_pos_all  |&gt;\n  filter(\n    !lemma %in% sw,\n    !upos %in% c(\"NUM\", \"SYM\", \"X\", \"PUNCT\"),\n    str_detect(lemma, \"^[\\\\p{L}-]+$\")\n  ) |&gt;\n  select(doc_id, lemma)\n\nnested_articles &lt;- articles_tokens_pruned |&gt;\n  nest(lemma = c(lemma))\n\narticles_windows &lt;- nested_articles |&gt;\n  mutate(lemma = map(lemma, slide_windows, 4L))  |&gt;\n  unnest(lemma) |&gt;\n  unite(window_id, doc_id, window_id)\n\narticles_pmi  &lt;- articles_windows  |&gt;\n  pairwise_pmi(lemma, window_id)\n\narticles_ppmi &lt;- articles_pmi |&gt;\n  mutate(ppmi = case_when(pmi &lt; 0 ~ 0,\n                          .default = pmi))\n\nДавайте посмотрим на полученную таблицу. Для preview я взяла 10 последних строк. Мне нравится, как получилось! Полную таблицу как всегда предлагаю забрать по ВСТАВИТЬ_ссылке.\n\n\n\n\n\n\n\n\nitem1\nitem2\npmi\nppmi\n\n\n\n\nсмолл-толка\nчасовой\n6.640088\n6.640088\n\n\nнебольшой\nсмолл-толка\n5.030650\n5.030650\n\n\nруководитель\nсмолл-толка\n3.713349\n3.713349\n\n\nподобный\nсмолл-толка\n5.136011\n5.136011\n\n\nповедение\nсмолл-толка\n5.541476\n5.541476\n\n\nбеседа\nсмолл-толка\n6.234623\n6.234623\n\n\nчасовой\nсмолл-толка\n6.640088\n6.640088\n\n\nотправлять\nпочта\n6.468238\n6.468238\n\n\nсрок\nпочта\n4.560647\n4.560647\n\n\nотклик\nпочта\n7.620918\n7.620918\n\n\n\n\n\n\n\nТеперь визуализирую полученные результаты.\n\nset.seed(123)\nword_emb &lt;- articles_ppmi |&gt;\n  widely_svd(item1, item2, ppmi,\n             weight_d = FALSE, nv = 100)\n\npal2 &lt;- RColorBrewer::brewer.pal(9, \"Blues\")[5:9]\n\nword_emb |&gt;\n  filter(dimension &lt; 4) |&gt;\n  mutate(dimension = factor(dimension)) |&gt;\n  group_by(dimension) |&gt;\n  top_n(5, abs(value)) |&gt;\n  ungroup() |&gt;\n  ggplot(aes(reorder_within(item1, value, dimension), value, fill = dimension)) +\n  geom_col(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~dimension, scales = \"free_y\", ncol = 3) +\n  scale_x_reordered() +\n  scale_fill_manual(values = pal2) +\n  coord_flip() +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Первые 3 главные тематики статей за все время\",\n    subtitle = \"Топ-5 слов\"\n  ) +\n  theme_light() +\n  theme(text = element_text(size = 14, family = \"Montserrat Medium\"),\n        strip.background = element_rect(fill = \"#D0CECE\"),\n        strip.text = element_text(color = \"black\"))\n\n\n\n\n\n\n\n\nЧестно говоря, мне не очень нравятся полученные результаты. Во втором топике слово руководитель явно выбивается из контекста, а во втором топике слова партнер и РАМ тоже явно лишние. Тем не менее первый топик получился совершенно ярко выраженным и легко интерпретируемым. В нем все про командную работу, трудоустройство и особенности найма в ИТ.\nС другой стороны, я понимаю, что на 13 статьях не построишь адекватно топики, потому что данных слишком мало. Именно поэтому я так и не решилась на проведение тематического моделирования этого пула статей.\nМожно будет масштабировать исследования и применить его не только к статьям компании, а к статьям на Хабре за 2025 год! Было бы интересно посмотреть, что так получится)\nСпасибо большое, что дочитали до конца! И прошу прощения за возможные очепятки. Буду очень рада обратной связи)"
  },
  {
    "objectID": "nlp.html#footnotes",
    "href": "nlp.html#footnotes",
    "title": "Crosstech Solutions Group",
    "section": "Сноски",
    "text": "Сноски\n\n\nЗакон Ципфа↩︎\nAI & ML Trends in Cloud-Native Infrastructure↩︎\nОт идеи до первого выпуска: как и зачем мы запустили подкаст про ИБ?↩︎\nКак организовать внутренний митап, чтобы он зашел команде? Наши принципы и немного истории↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Crosstech Solutions Group",
    "section": "",
    "text": "Crosstech Solutions Group (далее – CTSG/КТСГ) – российский разработчик инновационных решений для комплексной защиты информации бизнеса. Компания предлагает готовые решения, осуществляет заказную разработку и предоставляет ИТ-услуги в области кибербезопасности. Представлена на рынке ИБ с 2018 года.\nПродуктовый портфель КТСГ на сегодняшний день насчитывает 11 продуктов. Все они разработаны на основе глубоких исследований рынка информационной безопасности и закрепили за собой статус высокоэффективных средств защиты информации, пройдя апробацию в крупнейших компаниях различных отраслей экономики России. ИБ-продукты включены в реестр отечественного ПО Минцифры России и рекомендованы для импортозамещения на российских предприятиях.\nКомпания активно развивается не только со стороны разработки и поставки ПО, но и со стороны PR и маркетинга. Так, компания ведет соц. сети для повышения узнаваемости продуктов и развития бренда:\n\nTelegram-канал;\nгруппа ВКонтакте;\nХабр и др."
  },
  {
    "objectID": "index.html#о-компании",
    "href": "index.html#о-компании",
    "title": "Crosstech Solutions Group",
    "section": "",
    "text": "Crosstech Solutions Group (далее – CTSG/КТСГ) – российский разработчик инновационных решений для комплексной защиты информации бизнеса. Компания предлагает готовые решения, осуществляет заказную разработку и предоставляет ИТ-услуги в области кибербезопасности. Представлена на рынке ИБ с 2018 года.\nПродуктовый портфель КТСГ на сегодняшний день насчитывает 11 продуктов. Все они разработаны на основе глубоких исследований рынка информационной безопасности и закрепили за собой статус высокоэффективных средств защиты информации, пройдя апробацию в крупнейших компаниях различных отраслей экономики России. ИБ-продукты включены в реестр отечественного ПО Минцифры России и рекомендованы для импортозамещения на российских предприятиях.\nКомпания активно развивается не только со стороны разработки и поставки ПО, но и со стороны PR и маркетинга. Так, компания ведет соц. сети для повышения узнаваемости продуктов и развития бренда:\n\nTelegram-канал;\nгруппа ВКонтакте;\nХабр и др."
  },
  {
    "objectID": "index.html#цель-исследования",
    "href": "index.html#цель-исследования",
    "title": "Crosstech Solutions Group",
    "section": "Цель исследования",
    "text": "Цель исследования\nВ рамках учебной работы представлен анализ публикационной активности компании на Хабре. Я применила количественные методы, чтобы решить следующие задачи:\n\nопределить самые популярные статьи компании с учетом нескольких показателей;\nвыявить тематические направления, вызывающие наибольший интерес у аудитории;\nвизуализировать полученные результаты.\n\nЯ получила большое удовольствое в процессе работы. Надеюсь, тебе понравятся ее результаты ;)\nПоехали!"
  },
  {
    "objectID": "index.html#веб-скрапинг",
    "href": "index.html#веб-скрапинг",
    "title": "Crosstech Solutions Group",
    "section": "Веб-скрапинг",
    "text": "Веб-скрапинг\nНа начальном этапе я скрапила все опубликованные статьи компании на Хабре. В основном работала с пакетом rvest, но в одном случае понадобилось открыть сессию через chromote. Но об этом позже.\nСначала привязала все библиотеки.\n\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(polite)\nlibrary(xml2)\nlibrary(chromote)\nlibrary(lubridate)\n\nСобрала названия всех статей и ссылки на них. Привела это к тайди-формату и подготовила первую таблицу.\n\nurl &lt;- \"https://habr.com/ru/companies/ctsg/articles/\"\n\n# создаю \"виртуальный браузер\" для легитимизации действий парсера\nsession &lt;- bow(url)\nhtml &lt;- scrape(session)\n\n# сохраняю себе названия статей, класс определила через SelectorGadget\nelements &lt;- html |&gt; \n  html_elements(\".tm-title__link\")\n\n# сохраняю таблицу, в которую складываю названия статей и ссылки на них\n# все это хранится в теге \"a\"\narticles &lt;- tibble(\n  title = elements |&gt;\n    html_text2(),\n  href = elements |&gt; \n    html_attr(\"href\")\n)\n\n# добавляю протокол и домен к \"половинчатым\" сслыкам\narticles &lt;- articles |&gt; \n  mutate(link = str_c(\"https://habr.com\", href)) |&gt; \n  select(-href)\n\n# сохраняю вектор ссылок на статьи\nurls &lt;- articles |&gt; \n  pull(link)\n\nПо итогу получилась такая табличка.\n\n\n\n\n\n\n\n\ntitle\nlink\n\n\n\n\nКак создать решение в области контейнерной безопасности: подводные камни, проблемы и их решение\nhttps://habr.com/ru/companies/ctsg/articles/972514/\n\n\nPAM в информационной безопасности: ценный актив или бесполезный сотрудник?\nhttps://habr.com/ru/companies/ctsg/articles/918904/\n\n\nХакатоны только для гениев? Разбираем самые популярные заблуждения\nhttps://habr.com/ru/companies/ctsg/articles/893028/\n\n\nОт идеи до первого выпуска: как и зачем мы запустили подкаст про ИБ?\nhttps://habr.com/ru/companies/ctsg/articles/882176/\n\n\nКто такие DevSecOps -инженеры и зачем они нужны?\nhttps://habr.com/ru/companies/ctsg/articles/867704/\n\n\nКак с нуля построить систему обработки событий\nhttps://habr.com/ru/companies/ctsg/articles/842186/\n\n\nКак организовать внутренний митап, чтобы он зашел команде? Наши принципы и немного истории\nhttps://habr.com/ru/companies/ctsg/articles/831464/\n\n\nХочу стать тимлидом: как выбрать свой путь от специалиста в руководители\nhttps://habr.com/ru/companies/ctsg/articles/819323/\n\n\nСекреты успешного собеседования: как получить оффер технарю\nhttps://habr.com/ru/companies/ctsg/articles/818243/\n\n\nКак тимлиду проводить собеседование так, чтобы кандидат и компания получили от него максимум\nhttps://habr.com/ru/companies/ctsg/articles/808311/\n\n\nРаспознавание лиц на микрокомпьютерах\nhttps://habr.com/ru/companies/ctsg/articles/807069/\n\n\nЭффективные вложения в ИТ: Как посчитать ROI при внедрении ПО на примере системы маскирования данных\nhttps://habr.com/ru/companies/ctsg/articles/805255/\n\n\nКак выжить на первом испытательном сроке в IT и не только\nhttps://habr.com/ru/companies/ctsg/articles/803979/\n\n\n\n\n\n\n\nЗатем написала функцию, которая пройдется по всей таблице с ссылками на статьи и соберет нужные мне для анализа данные. В данном случае функция будет “вытаскивать”:\n\nтексты статей;\nдата;\nвремя публикации;\nвремя чтения;\nколичество голосов (грубо говоря, лайков);\nколичество добавлений в избранное;\nчисло комментариев;\nтеги, хабы;\nуровень сложности текста.\n\n\nget_article_polite &lt;- function(url) {\n  bow_obj &lt;- bow(url)\n  \n  html_page &lt;- scrape(bow_obj)\n  \n  months_dict &lt;- c(\n    \"янв\" = \"01\",\n    \"фев\" = \"02\",\n    \"мар\" = \"03\",\n    \"апр\" = \"04\",\n    \"мая\" = \"05\",\n    \"июн\" = \"06\",\n    \"июл\" = \"07\",\n    \"авг\" = \"08\",\n    \"сен\" = \"09\",\n    \"окт\" = \"10\",\n    \"ноя\" = \"11\",\n    \"дек\" = \"12\"\n  )\n  \n  date = html_page |&gt; \n    html_elements(\".tm-article-presenter__snippet time\") |&gt; \n    html_text2() |&gt; \n    str_replace(\" в \", \" \") |&gt;\n    str_replace(\"\\\\d+:\\\\d+\", \"\")\n  \n  if (!str_detect(date, \"202\")) {date &lt;- paste(date, year(Sys.Date()))}\n  \n  res = tibble(\n    text = html_page |&gt;\n      html_elements(\".article-body\") |&gt; \n      html_text2() |&gt; \n      str_squish() |&gt;\n      str_remove(\"^\\\\[\\\\] \"),\n    date = date |&gt; \n      str_squish() |&gt; \n      str_replace_all(months_dict) |&gt; \n      dmy(),\n    time = html_page |&gt; \n      html_elements(\".tm-article-presenter__snippet time\") |&gt; \n      html_text2() |&gt; \n      str_extract(\"\\\\d+:\\\\d+\") |&gt; \n      hm(),\n    read_time_min = html_page |&gt; \n      html_elements(\".tm-article-presenter__snippet .tm-article-reading-time__label\") |&gt; \n      html_text2() |&gt; \n      str_extract(\"\\\\d+\") |&gt; \n      as.integer(),\n    votes = html_page |&gt; \n      html_element(\".tm-votes-lever__score_appearance-article span, .votes-switcher\") |&gt; \n      html_text2() |&gt; \n      str_extract(\"(?&lt;=\\\\+).\") |&gt;  # без этой регулярки отображается доп. инфа, необходимо взять только последнее число\n      as.integer(),\n    mark = html_page |&gt; \n      html_elements(\".tm-article-sticky-panel__icons .bookmarks-button\") |&gt; \n      html_text2() |&gt; \n      str_remove(\"Добавить в закладки\") |&gt; \n      as.integer(), \n    num_of_comments = html_page |&gt; \n      html_elements(\".tm-article-sticky-panel__icons .article-comments-counter-link-wrapper\") |&gt; \n      html_text2() |&gt; \n      str_remove(\"Комментарии\") |&gt; \n      as.integer(),\n    tags = html_page |&gt; \n      html_elements(\".tag-list\") |&gt; \n      html_text2() |&gt; \n      str_extract_all(\"(?&lt;=\\\\[).*?(?=\\\\])\") |&gt; \n      unlist() |&gt;\n      paste(collapse = \", \"),\n    hubs = html_page |&gt; \n      html_elements(\".tm-article-presenter__meta-list+ .tm-article-presenter__meta-list\") |&gt; \n      html_text2() |&gt; \n      str_extract_all(\"(?&lt;=\\\\[).*?(?=\\\\])\") |&gt; \n      unlist() |&gt;\n      paste(collapse = \", \"),\n    complexity_label = html_page |&gt; \n      html_element(\".tm-article-complexity_complexity-medium .tm-article-complexity__label\") |&gt; \n      html_text2()\n  )\n  \n  return(res)\n  \n}\n\nПрименяю функцию ко всем статьям через итератор\n\narticles_ctsg &lt;- map_df(urls, get_article_polite, .id = \"id\")\n\nИ в результате получаем следующее. В таблице ниже в некоторых ячейках обрезаны строки, чтобы визуальнее это смотрелось приятнее. На итоговый тиббл я оставлю ссылку для скачивания.\n\n\n\n\n\n\n\n\n\nid\ntext\ndate\ntime\nread_time_min\nvotes\nmark\nnum_of_comments\ntags\nhubs\ncomplexity_label\n\n\n\n\n1\nВсем привет! На связи Александр Синичкин, ведущий архитектор …\n2025-12-02\n13H 44M 0S\n9\n8\n9\n0\nконтейнеризация, контейнерная безопасность, разработка продукта, кейс, container security, …\nБлог компании Crosstech Solutions Group, Kubernetes, IT-инфраструктура, IT-компании\nСредний\n\n\n2\nPAM или партнерский менеджер — специалист, отвечающий за …\n2025-06-17\n7H 51M 0S\n7\n5\n2\n4\nпродажи в it, информационная безопасность, партнеры, партнерские отношения, …\nБлог компании Crosstech Solutions Group, Информационная безопасность\nNA\n\n\n3\nХакатон — это марафон в мире IT. Здесь …\n2025-03-21\n9H 30M 0S\n3\n6\n7\n1\nхакатон, командообразование, защита проекта, тестировщик, студенты it, студенты\nБлог компании Crosstech Solutions Group\nNA\n\n\n4\nПривет! Это Яна Ильина, HRBP CrossTech Solutions Group, …\n2025-02-13\n11H 29M 0S\n6\n6\n9\n2\nподкаст, бренд, выпуски, команда, информационная безопасность, спикеры\nБлог компании Crosstech Solutions Group, Информационная безопасность\nNA\n\n\n5\nДобрый день, уважаемые читатели! Сегодня я расскажу о …\n2024-12-18\n12H 30M 0S\n5\nNA\n13\n3\nDevSecOps -инженеры, информационная безопасность, тестирование, уязвимости\nБлог компании Crosstech Solutions Group\nNA\n\n\n6\nСегодня Александр Шувалов и Юлиян Латыпов поделятся с …\n2024-09-10\n10H 24M 0S\n7\n3\n28\n0\nданные, потоковая обработка, потоковая обработка данных\nБлог компании Crosstech Solutions Group, Анализ и проектирование …\nNA\n\n\n7\nВсем привет! Меня зовут Ульяна Петракова, я специалист …\n2024-07-25\n13H 8M 0S\n2\n4\n8\n1\nit-компании, карьера в it-индустрии, митап\nБлог компании Crosstech Solutions Group, Управление персоналом\nNA\n\n\n8\nКогда я работал программистом, мне было интересно не …\n2024-06-04\n7H 50M 0S\n17\n1\n40\n0\nуправление, тимлидство, путь в ит, развитие, менеджмент, лидерство\nБлог компании Crosstech Solutions Group, Управление разработкой, Управление …\nNA\n\n\n9\nПривет! Меня зовут Артём и когда-то я уже …\n2024-05-30\n8H 37M 0S\n11\n7\n44\n8\nсобеседование в it, подбор персонала, интервью, рекрутинг, интервью …\nБлог компании Crosstech Solutions Group, Карьера в IT-индустрии, …\nNA\n\n\n10\nВсем привет! С вами снова я, Артём Харченков, …\n2024-04-17\n7H 48M 0S\n12\n3\n20\n9\nкарьера в it-индустрии, it компании, информационная безопасность\nБлог компании Crosstech Solutions Group\nNA\n\n\n11\nВ последние годы появляется всё больше технологий с …\n2024-04-11\n14H 8M 0S\n9\n9\n52\n7\nинформационная безопасность, распознавание лиц\nБлог компании Crosstech Solutions Group, Машинное обучение\nNA\n\n\n12\nВсем привет! Меня зовут Али Гаджиев, я Директор …\n2024-04-04\n6H 28M 0S\n7\n4\n9\n2\nзащита данных, защита от утечек данных, субд\nБлог компании Crosstech Solutions Group, Хранение данных\nСредний\n\n\n13\nВсем привет! Меня зовут Артём Харченков, и я …\n2024-03-29\n14H 36M 0S\n13\n3\n105\n16\nиспытательный срок, информационная безопасность, подбор персонала\nБлог компании Crosstech Solutions Group, Информационная безопасность, Карьера …\nNA\n\n\n\n\n\n\n\n\nДалее делаю кое-какие преобразования, чтобы можно было собрать отдельную статистику по дням и по времени.\n\nmonths_dict2 &lt;- c(\n  \"янв\" = \"Jan\",\n  \"фев\" = \"Feb\",\n  \"мар\" = \"Mar\",\n  \"апр\" = \"Apr\",\n  \"май\" = \"May\",\n  \"июн\" = \"Jun\",\n  \"июл\" = \"Jul\",\n  \"авг\" = \"Aug\",\n  \"сен\" = \"Sep\",\n  \"окт\" = \"Oct\",\n  \"ноя\" = \"Nov\",\n  \"дек\" = \"Dec\"\n)\n\nweek_dict &lt;- c(\n  \"Пн\" = \"Mon\",\n  \"Вт\" = \"Tue\",\n  \"Ср\" = \"Wed\",\n  \"Чт\" = \"Thu\",\n  \"Пт\" = \"Fri\",\n  \"Сб\" = \"Sat\",\n  \"Вс\" = \"Sun\"\n)\n\narticles_ctsg &lt;- articles_ctsg |&gt; \n  mutate(year = year(date), \n         month = month(date, label = TRUE),\n         wday = wday(date, label = TRUE, locale = Sys.getlocale(\"LC_TIME\")),\n         hour = hour(time),\n         length = str_count(text, \"\\\\S+\")) |&gt; \n  mutate(month = str_replace_all(as.character(month), months_dict2), \n         wday = str_replace_all(as.character(wday), week_dict))\n\nВ Хабре не так давно прошло обновление. Теперь он показывает число уникальных пользователей, которые:\n\nОткрыли публикацию;\nОткрыли публикацию ИЛИ увидели еe в ленте.\n\nЗначит, второй показатель будет заведомо больше. И он позволит HR и PR-менеджерам делать дополнительные выводы в ходе анализа интересов аудитории.\nНажмите на картинку, чтобы ее приблизить.\n\n\n\n\nНо сам этот элемент является popup-элементом. Т.е. он открывается только при нажатии не него. Через SelectorGadget у меня не получилось до него достучаться, поэтому я использовала пакет chromote.\nИ затем я извлекаю количество просмотров.\n\nget_article_2 &lt;- function(url) {\n  b &lt;- ChromoteSession$new()\n  \n  b$Network$enable()\n  b$Network$setBlockedURLs(urls = list(\n    \"*googletagmanager.com/*\",\n    \"*google-analytics.com/*\",\n    \"*analytics.google.com/*\",\n    \"*mc.yandex.ru/*\",\n    \"*yandex.ru/ads/*\",\n    \"*vk.com/rtrg*\",\n    \"*sentry*\"\n  ))\n  b$Page$navigate(url)\n  b$Page$loadEventFired(wait_ = TRUE)\n  Sys.sleep(3)\n  \n  CLICK_SELECTOR &lt;- \".tm-article-presenter__snippet .reach-counter\"\n  \n  js_click &lt;- sprintf(\"\n  (function(){\n    var el = document.querySelector('%s');\n    if (el) { el.click(); return 'clicked'; }\n    else { return 'not found'; }\n  })();\n\", CLICK_SELECTOR)\n  \n  res &lt;- b$Runtime$evaluate(js_click)\n  \n  Sys.sleep(2)\n  \n  html &lt;- {\n    doc &lt;- b$DOM$getDocument()\n    root_id &lt;- doc$root$nodeId\n    b$DOM$getOuterHTML(nodeId = root_id)[['outerHTML']]\n  }\n  \n  page &lt;- read_html(html)\n  \n  res = tibble(\n    reach_value = page |&gt;\n      html_element(\".tm-modal-window .value\") |&gt;\n      html_text2() |&gt; \n      str_remove(\" охват\"),\n    unique_readers = page |&gt; \n      html_element(\".publication-metric+ .publication-metric .value\") |&gt;\n      html_text2() |&gt; \n      str_remove(\" читател(ей|я|ь)\")\n  )\n  \n  return(res)\n  \n}\n\narticles_ctsg_2 &lt;- map_df(urls, get_article_2, .id = \"id\")\n\nВ хабре количество просмотров, превыщающее 1 тысячу, обозначается через К, например, 1.2к - 1200 просмотров. Ниже будет представлена функция, которая будет извлекать приблизительное число просмотров и переводить его в числовой формат. Да, значение получится округленным, но это зато примет более нормализованный вид.\n\nchange_views &lt;- function(vec) {\n  map_int(vec, ~ {\n    x &lt;- .x\n    # если запись содержит символ точки или \"К\"\n    if (is.na(as.integer(x)) == \"TRUE\") {\n      # сначала удаляю \"K\"\n      x &lt;- str_remove(x, \"K\")\n      # если после удаления \"К\" есть еще один ненужный элемент - точка\n      if (str_detect(x, \"\\\\.\")) {\n        # то удаляем точку\n        x &lt;- str_remove(x, \"\\\\.\")\n        # и приписываем два нуля (условно умножаем на тысячу)\n        x &lt;- str_c(x, \"00\")\n        # переводим к целочисленному типу\n        x &lt;- as.integer(x)\n      } \n      else {\n        # если точки нет, то просто приписываем 3 нуля (будто умножаем на тысячу)\n        # и переводим к целому типу\n        x &lt;- str_c(x, \"000\")\n        x &lt;- as.integer(x)\n      }\n    }\n    # если нет ни точки, ни \"К\", то просто переводим к целому типу данных\n    else {\n      x &lt;- as.integer(x)\n    }\n  })\n}\n\nПрименяю функцию к полученному тибблу.\n\narticles_ctsg_2 &lt;- articles_ctsg_2 |&gt; \n  mutate(reach_value = change_views(reach_value)) |&gt; \n  mutate(unique_readers = change_views(unique_readers)) |&gt; \n  mutate(id = as.integer(id))\n\nИ получается такая милая табличка.\n\n\n\n\n\n\n\n\nid\nreach_value\nunique_readers\n\n\n\n\n1\n7300\n677\n\n\n2\n478\n478\n\n\n3\n751\n751\n\n\n4\n703\n703\n\n\n5\n2100\n2100\n\n\n6\n2200\n2200\n\n\n7\n743\n743\n\n\n8\n2100\n2100\n\n\n9\n3800\n3800\n\n\n10\n4000\n4000\n\n\n11\n5400\n5400\n\n\n12\n2900\n2900\n\n\n13\n23000\n23000"
  },
  {
    "objectID": "index.html#обработка-данных",
    "href": "index.html#обработка-данных",
    "title": "Crosstech Solutions Group",
    "section": "Обработка данных",
    "text": "Обработка данных\nПосле того как все данные собраны, я делаю дополнительные преобзования. Во-первых, разделяю колонки с датами на отдельные колонки, добавляю колонку с количеством слов в тексте, и заменяю значения месяцев и дней недели по словарям.\n\nmonths_dict2 &lt;- c(\n  \"янв\" = \"Jan\",\n  \"фев\" = \"Feb\",\n  \"мар\" = \"Mar\",\n  \"апр\" = \"Apr\",\n  \"май\" = \"May\",\n  \"июн\" = \"Jun\",\n  \"июл\" = \"Jul\",\n  \"авг\" = \"Aug\",\n  \"сен\" = \"Sep\",\n  \"окт\" = \"Oct\",\n  \"ноя\" = \"Nov\",\n  \"дек\" = \"Dec\"\n)\n\nweek_dict &lt;- c(\n  \"Пн\" = \"Mon\",\n  \"Вт\" = \"Tue\",\n  \"Ср\" = \"Wed\",\n  \"Чт\" = \"Thu\",\n  \"Пт\" = \"Fri\",\n  \"Сб\" = \"Sat\",\n  \"Вс\" = \"Sun\"\n)\n\narticles_ctsg &lt;- articles_ctsg |&gt; \n  mutate(year = year(date), \n         month = month(date, label = TRUE),\n         wday = wday(date, label = TRUE, locale = Sys.getlocale(\"LC_TIME\")),\n         hour = hour(time),\n         length = str_count(text, \"\\\\S+\")) |&gt; \n  mutate(month = str_replace_all(as.character(month), months_dict2), \n         wday = str_replace_all(as.character(wday), week_dict))\n\nВо-вторых, добавляю отдельную колонку с ID статьи. Также преобразовываю общую колонку с временем и отдельную колонку с часами: прибавляю +3 часа, чтобы отображаемое время публикации статьи было московским.\n\narticles_ctsg &lt;- articles_ctsg |&gt; \n  mutate(id = as.integer(id),\n         time = time + hours(3),\n         hour = hour + 3)\n\n# добавляю к исходному тибблу с названиями статей и ссылками на них идентификатор\narticles &lt;- articles |&gt; \n  mutate(id = row_number())\n\nВ-третьих, делаю два иннер-джойна (ведь таблиц у меня 3, за раз можно объединить только 2).\n\narticles_ctsg &lt;- articles_ctsg |&gt; \n  inner_join(articles_ctsg_2, by = \"id\")\n\n# объединяю две таблицы через inner join (т.к. здесь нет пропусков)\narticles_ctsg_full &lt;- inner_join(articles, articles_ctsg, by = \"id\") |&gt; \n  select(id, title, text, length, link, complexity_label, date, year, month, wday, hour, time, read_time_min, reach_value, unique_readers, votes, mark, num_of_comments, tags, hubs)\n\nИ у меня получается общая таблица со всеми собранными данными. Целая таблица для скачивания представлена по ссылке.\nОбращаю внимание, что при воспроизведении кода результаты могут немного изменяться. Это связано с тем, что я локально прогнала этот код и подгрузила его в проект, чтобы облегчить работу рендеру. Поэтому у Вас могут быть другие показатели как минимум просмотров.\n\n\n\n\n\n\n\n\n\nid\ntitle\ntext\nlength\nlink\ncomplexity_label\ndate\nyear\nmonth\nwday\nhour\ntime\nread_time_min\nreach_value\nunique_readers\nvotes\nmark\nnum_of_comments\ntags\nhubs\n\n\n\n\n1\nКак создать решение в области контейнерной безопасности: подводные камни, проблемы и их решение\nВсем привет! На связи Александр Синичкин, ведущий архитектор …\n1851\nhttps://habr.com/ru/...\nСредний\n2025-12-02\n2025\nDec\nTue\n16\n16H 44M 0S\n9\n7300\n677\n8\n9\n0\nконтейнеризация, контейнерная безопасность, …\nБлог компании Crosstech …\n\n\n2\nPAM в информационной безопасности: ценный актив или бесполезный сотрудник?\nPAM или партнерский менеджер — специалист, отвечающий за …\n1420\nhttps://habr.com/ru/...\nNA\n2025-06-17\n2025\nJun\nTue\n10\n10H 51M 0S\n7\n478\n478\n5\n2\n4\nпродажи в it, …\nБлог компании Crosstech …\n\n\n3\nХакатоны только для гениев? Разбираем самые популярные заблуждения\nХакатон — это марафон в мире IT. Здесь …\n652\nhttps://habr.com/ru/...\nNA\n2025-03-21\n2025\nMar\nFri\n12\n12H 30M 0S\n3\n751\n751\n6\n7\n1\nхакатон, командообразование, защита …\nБлог компании Crosstech …\n\n\n4\nОт идеи до первого выпуска: как и зачем мы запустили подкаст про ИБ?\nПривет! Это Яна Ильина, HRBP CrossTech Solutions Group, …\n1172\nhttps://habr.com/ru/...\nNA\n2025-02-13\n2025\nFeb\nThu\n14\n14H 29M 0S\n6\n703\n703\n6\n9\n2\nподкаст, бренд, выпуски, …\nБлог компании Crosstech …\n\n\n5\nКто такие DevSecOps -инженеры и зачем они нужны?\nДобрый день, уважаемые читатели! Сегодня я расскажу о …\n1033\nhttps://habr.com/ru/...\nNA\n2024-12-18\n2024\nDec\nWed\n15\n15H 30M 0S\n5\n2100\n2100\nNA\n13\n3\nDevSecOps -инженеры, информационная …\nБлог компании Crosstech …\n\n\n6\nКак с нуля построить систему обработки событий\nСегодня Александр Шувалов и Юлиян Латыпов поделятся с …\n1354\nhttps://habr.com/ru/...\nNA\n2024-09-10\n2024\nSep\nTue\n13\n13H 24M 0S\n7\n2200\n2200\n3\n28\n0\nданные, потоковая обработка, …\nБлог компании Crosstech …\n\n\n7\nКак организовать внутренний митап, чтобы он зашел команде? Наши принципы и немного истории\nВсем привет! Меня зовут Ульяна Петракова, я специалист …\n367\nhttps://habr.com/ru/...\nNA\n2024-07-25\n2024\nJul\nThu\n16\n16H 8M 0S\n2\n743\n743\n4\n8\n1\nit-компании, карьера в …\nБлог компании Crosstech …\n\n\n8\nХочу стать тимлидом: как выбрать свой путь от специалиста в руководители\nКогда я работал программистом, мне было интересно не …\n4323\nhttps://habr.com/ru/...\nNA\n2024-06-04\n2024\nJun\nTue\n10\n10H 50M 0S\n17\n2100\n2100\n1\n40\n0\nуправление, тимлидство, путь …\nБлог компании Crosstech …\n\n\n9\nСекреты успешного собеседования: как получить оффер технарю\nПривет! Меня зовут Артём и когда-то я уже …\n2766\nhttps://habr.com/ru/...\nNA\n2024-05-30\n2024\nMay\nThu\n11\n11H 37M 0S\n11\n3800\n3800\n7\n44\n8\nсобеседование в it, …\nБлог компании Crosstech …\n\n\n10\nКак тимлиду проводить собеседование так, чтобы кандидат и компания получили от него максимум\nВсем привет! С вами снова я, Артём Харченков, …\n3032\nhttps://habr.com/ru/...\nNA\n2024-04-17\n2024\nApr\nWed\n10\n10H 48M 0S\n12\n4000\n4000\n3\n20\n9\nкарьера в it-индустрии, …\nБлог компании Crosstech …\n\n\n11\nРаспознавание лиц на микрокомпьютерах\nВ последние годы появляется всё больше технологий с …\n2022\nhttps://habr.com/ru/...\nNA\n2024-04-11\n2024\nApr\nThu\n17\n17H 8M 0S\n9\n5400\n5400\n9\n52\n7\nинформационная безопасность, распознавание …\nБлог компании Crosstech …\n\n\n12\nЭффективные вложения в ИТ: Как посчитать ROI при внедрении ПО на примере системы маскирования данных\nВсем привет! Меня зовут Али Гаджиев, я Директор …\n1633\nhttps://habr.com/ru/...\nСредний\n2024-04-04\n2024\nApr\nThu\n9\n9H 28M 0S\n7\n2900\n2900\n4\n9\n2\nзащита данных, защита …\nБлог компании Crosstech …\n\n\n13\nКак выжить на первом испытательном сроке в IT и не только\nВсем привет! Меня зовут Артём Харченков, и я …\n3348\nhttps://habr.com/ru/...\nNA\n2024-03-29\n2024\nMar\nFri\n17\n17H 36M 0S\n13\n23000\n23000\n3\n105\n16\nиспытательный срок, информационная …\nБлог компании Crosstech …"
  },
  {
    "objectID": "index.html#анализ-данных",
    "href": "index.html#анализ-данных",
    "title": "Crosstech Solutions Group",
    "section": "Анализ данных",
    "text": "Анализ данных\nТеперь мне было интересно узнать, какие статьи компании оказались самыми популярными. Выводы необходимо делать на основании тех показателей, которые были получены во время сбора данных.\nТак, я решила посмотреть ТОП-5 статей по следующим данным:\n\nПросмотры (по первому и второму показателю просмотров Хабра);\nЧисло голосов;\nЧисло добавлений статей в Избранные;\nЧисло комментариев.\n\n\nmost_viewed1 &lt;- articles_ctsg_full |&gt; \n  arrange(desc(unique_readers)) |&gt; \n  head(5)\n\nmost_viewed2 &lt;- articles_ctsg_full |&gt; \n  arrange(desc(reach_value)) |&gt; \n  head(5)\n\nmost_votes &lt;- articles_ctsg_full |&gt; \n  arrange(desc(votes)) |&gt; \n  head(5)\n\nmost_marked &lt;- articles_ctsg_full |&gt; \n  arrange(desc(mark))|&gt; \n  head(5)\n\nmost_commented &lt;- articles_ctsg_full |&gt; \n  arrange(desc(num_of_comments))|&gt; \n  head(5)\n\nСохраняю ID тех статей, которые являются наиболее значимыми с разных точек зрения (читатели, охват, оценки, комментарии), и формирует итоговый список “ключевых” публикаций компании. После формирую общую таблицу.\n\nall_ids &lt;- unique(c(\n  most_viewed1$id,\n  most_viewed2$id,\n  most_votes$id,\n  most_marked$id,\n  most_commented$id\n))\n\nresult &lt;- tibble(\n  id = all_ids,\n  in_most_viewed1 = id %in% most_viewed1$id,\n  in_most_viewed2 = id %in% most_viewed2$id,\n  in_most_votes = id %in% most_votes$id,\n  in_most_marked = id %in% most_marked$id,\n  in_most_commented = id %in% most_commented$id\n)\n\nЗдесь мы видим, какие статьи входят во все топы, но еще не хватает некоторой структуры.\n\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(gt)\n\nresult |&gt;\n  gt() |&gt;\n  opt_table_outline() |&gt;\n  \n  tab_options(\n    table.width = px(500)\n  ) |&gt;\n\n  # Цвет текста (чуть темнее базового spacelab)\n  tab_style(\n    style = cell_text(color = \"#2f3a45\"),\n    locations = cells_body()\n  ) |&gt;\n\n  # Шапка таблицы\n  tab_style(\n    style = list(\n      cell_fill(color = \"#eef5ff\"),\n      cell_text(weight = \"bold\", color = \"#2f3a45\")\n    ),\n    locations = cells_column_labels()\n  ) |&gt;\n\n  # Hover-эффект для строк\n  opt_css(\n    css = \"\n      tbody tr:hover {\n        background-color: #f7fbff;\n      }\n    \"\n)\n\n\n\n\n\n\n\nid\nin_most_viewed1\nin_most_viewed2\nin_most_votes\nin_most_marked\nin_most_commented\n\n\n\n\n13\nTRUE\nTRUE\nFALSE\nTRUE\nTRUE\n\n\n11\nTRUE\nTRUE\nTRUE\nTRUE\nTRUE\n\n\n10\nTRUE\nTRUE\nFALSE\nFALSE\nTRUE\n\n\n9\nTRUE\nTRUE\nTRUE\nTRUE\nTRUE\n\n\n12\nTRUE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\n1\nFALSE\nTRUE\nTRUE\nFALSE\nFALSE\n\n\n3\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\n\n\n4\nFALSE\nFALSE\nTRUE\nFALSE\nFALSE\n\n\n8\nFALSE\nFALSE\nFALSE\nTRUE\nFALSE\n\n\n6\nFALSE\nFALSE\nFALSE\nTRUE\nFALSE\n\n\n2\nFALSE\nFALSE\nFALSE\nFALSE\nTRUE\n\n\n\n\n\n\n\nПоэтому надо просуммировать все строчки и отсортировать по общей сумме. И соединить эту таблицу с последней, чтобы она содержала все данные по каждой “топовой” статье.\n\nresult &lt;- result |&gt; \n  mutate(total_hits = rowSums(across(starts_with(\"in_\")))) |&gt; \n  arrange(desc(total_hits)) |&gt; \n  inner_join(articles_ctsg_full, by = \"id\") |&gt; \n  select(total_hits, id, title, text, length, link, complexity_label, date, year, month, wday, hour, time, read_time_min, reach_value, unique_readers, votes, mark, num_of_comments, tags, hubs) |&gt;\n  head(5) |&gt; \n  mutate(hit_id = row_number()) |&gt; \n  mutate(hit_id = as.integer(hit_id))\n\nresult &lt;- result |&gt; \n  select(hit_id, total_hits, id, title, text, length, link, complexity_label, date, year, month, wday, hour, time, read_time_min, reach_value, unique_readers, votes, mark, num_of_comments, tags, hubs)\n\nПолучилась такая таблица. Забрать целую таблицу можно по ссылке. Также дисклеймер, что данные при воспроизведении могут отличаться от представленных.\n\n\n\n\n\n\n\n\n\nhit_id\ntotal_hits\nid\ntitle\ntext\nlength\nlink\ncomplexity_label\ndate\nyear\nmonth\nwday\nhour\ntime\nread_time_min\nreach_value\nunique_readers\nvotes\nmark\nnum_of_comments\ntags\nhubs\n\n\n\n\n1\n5\n11\nРаспознавание лиц на …\nВ последние годы появляется …\n2022\nhttps://habr.com/ru/...\nNA\n2024-04-11\n2024\nApr\nThu\n17\n17H 8M 0S\n9\n5400\n5400\n9\n52\n7\nинформационная безопасность, …\nБлог компании …\n\n\n2\n5\n9\nСекреты успешного собеседования: …\nПривет! Меня зовут Артём …\n2766\nhttps://habr.com/ru/...\nNA\n2024-05-30\n2024\nMay\nThu\n11\n11H 37M 0S\n11\n3800\n3800\n7\n44\n8\nсобеседование в …\nБлог компании …\n\n\n3\n4\n13\nКак выжить на …\nВсем привет! Меня зовут …\n3348\nhttps://habr.com/ru/...\nNA\n2024-03-29\n2024\nMar\nFri\n17\n17H 36M 0S\n13\n23000\n23000\n3\n105\n16\nиспытательный срок, …\nБлог компании …\n\n\n4\n3\n10\nКак тимлиду проводить …\nВсем привет! С вами …\n3032\nhttps://habr.com/ru/...\nNA\n2024-04-17\n2024\nApr\nWed\n10\n10H 48M 0S\n12\n4000\n4000\n3\n20\n9\nкарьера в …\nБлог компании …\n\n\n5\n2\n1\nКак создать решение …\nВсем привет! На связи …\n1851\nhttps://habr.com/ru/...\nСредний\n2025-12-02\n2025\nDec\nTue\n16\n16H 44M 0S\n9\n7300\n677\n8\n9\n0\nконтейнеризация, контейнерная …\nБлог компании …\n\n\n\n\n\n\n\n\nИтого, в общий ТОП-5 вошли следующие статьи:\n\nРаспознавание лиц на микрокомпьютерах1;\nСекреты успешного собеседования: как получить оффер технарю2;\nКак выжить на первом испытательном сроке в IT и не только3;\nКак тимлиду проводить собеседование так, чтобы кандидат и компания получили от него максимум4;\nКак создать решение в области контейнерной безопасности: подводные камни, проблемы и их решение5.\n\nЧуть позже я попытаюсь сделать выводы о том, почему именно такие статьи оказались наиболоее востребованными у аудитории, предварительно рассмотрев некоторые лексические особенности этих текстов. А пока предлагаю ознакомиться с незамысловатой визуаилизацией, которую я подготовила по обработанным данным :)"
  },
  {
    "objectID": "index.html#визуализация",
    "href": "index.html#визуализация",
    "title": "Crosstech Solutions Group",
    "section": "Визуализация",
    "text": "Визуализация\nТаблицы нам уже могут рассказать некоторую особенность, но визуализация не только дает красивую картинку, но и помогает выявить интересные закономерности в данных. Предлагаю ознакомиться с тем, что у меня получилось!\nСделаю замечание, что здесь представлена статистика по ВСЕМ статьям компании на Хабре, а не только по самым популярным.\nПодгружаю библиотеки.\n\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(paletteer)\nlibrary(extrafont)\nlibrary(plotly)\nlibrary(dplyr)\n\nЗдесь я хочу посмотреть число статей по месяцам. Для этого сначала посчитаю, сколько статей было написано за определенный год и месяц.\n\nmonth_order &lt;- c(\n  \"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\n  \"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"\n)\n\nyears_order &lt;- c(2024, 2025)\n\narticles_ctsg_full_p1 &lt;- articles_ctsg_full |&gt; \n  count(year, month, sort = FALSE) |&gt; \n  tidyr::complete(\n    year = years_order,\n    month = month_order,\n    fill = list(n = 0)\n  ) |&gt;\n  mutate(\n    month = factor(month, levels = month_order),\n    year  = factor(year)\n  ) |&gt;\n  rename(count = n)\n\nВ целом, это уже готово к визуализации. Только делаю некоторые махинации с палитрой и шрифтом. Предварительно скачиваю фон Montserrat, его можно забрать здесь.\n\nfont_import()  \nloadfonts(device = \"win\")\n\nИ готовю график. Сначала через ggplot, потом “оживляю” график через plotly.\n\np1 &lt;- articles_ctsg_full_p1 |&gt; \n  mutate(month = factor(month, levels = month_order),\n         year  = factor(year)) |&gt;\n  ggplot(aes(x = month,\n             y = count,\n             fill = year)) +\n  geom_col(alpha = 0.8, na.rm = TRUE) +\n  scale_fill_manual(name = \"Год\",\n                    values = c(\"2024\" = \"#3A77B9\", \"2025\" = \"#385E8C\")) +\n  scale_x_discrete(labels = month_order) +\n  labs(title = \"Число статей по месяцам\",\n       x = NULL, y = NULL) +\n  theme(\n    panel.background = element_rect(fill = \"white\", color = NA),\n    panel.grid.major = element_line(color = \"grey85\", linewidth = 0.4),\n    panel.grid.minor = element_line(color = \"grey92\", linewidth = 0.3),\n    text = element_text(size = 14, family = \"Montserrat Medium\"))\n\nggplotly(p1) |&gt; \n  layout(\n    legend = list(\n      x = 1.05,\n      y = 0.5,\n      xanchor = \"left\",\n      yanchor = \"middle\",\n      title = list(\n        text = \"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Год\"\n      )\n    )\n  )\n\n\n\n\n\nАпрель 2024 года был самым продуктивным годом. 2 из 5 самых популярных статей были опубликованы в этот период.\nТеперь рассмотрим статьи по дням недели. Для этого в первую очередь необходимо посчитать число статей по годам и дням недели.\n\nweek_order &lt;- c(\n  \"Fri\", \"Thu\", \"Wed\", \"Tue\", \"Mon\" \n)\n\nyears_order &lt;- c(2024, 2025)\n\narticles_ctsg_full_p2 &lt;- articles_ctsg_full |&gt; \n  count(year, wday, sort = FALSE) |&gt; \n  tidyr::complete(\n    year = years_order,\n    wday = week_order,\n    fill = list(n = 0)\n  ) |&gt;\n  mutate(\n    year  = factor(year)\n  ) |&gt;\n  rename(count = n)\n\nДанные для визуализации готовы! Логика остается та же.\n\np2 &lt;- articles_ctsg_full_p2 |&gt;\n  mutate(\n    wday = factor(wday, levels = week_order),\n    year = factor(year)\n  ) |&gt;\n  ggplot(aes(x = wday,\n             y = count,\n             fill = year)) +\n  geom_col(alpha = 0.8, na.rm = TRUE) +\n  coord_flip() +\n  scale_fill_manual(\n    name = \"Год\",\n    values = c(\"2024\" = \"#3A77B9\", \"2025\" = \"#385E8C\")\n  ) +\n  scale_x_discrete(labels = week_order) +\n  labs(\n    title = \"Статьи по дням недели\",\n    x = NULL, y = NULL\n  ) +\n  theme(\n    panel.background = element_rect(fill = \"white\", color = NA),\n    panel.grid.major = element_line(color = \"grey85\", linewidth = 0.4),\n    panel.grid.minor = element_line(color = \"grey92\", linewidth = 0.3),\n    text = element_text(size = 14, family = \"Montserrat Medium\")\n  )\n\nggplotly(p2) |&gt; \n  layout(\n    legend = list(\n      x = 1.05,\n      y = 0.5,\n      xanchor = \"left\",\n      yanchor = \"middle\",\n      title = list(\n        text = \"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Год\"\n      )\n    )\n  )\n\n\n\n\n\nСамыми “активными” для публикаций днями являются вторник и четверг. Эти дни выбраны не просто так, об этом пишут специалисты6.\nНу и посмотрим последний (в этом разделе!) график, в котором представлены длины статей по годам.\n\np3 &lt;- articles_ctsg_full |&gt; \n  ggplot(aes(as.factor(year), length, fill = as.factor(year))) +\n  geom_boxplot(show.legend = FALSE) +\n  scale_fill_manual(\n    name = \"Год\",\n    values = c(\"2024\" = \"#3A77B9\", \"2025\" = \"#385E8C\")\n  ) +\n  labs(title = \"Длина статьи по годам\") + \n  labs(x = NULL, y = NULL) + \n  theme(\n    panel.background = element_rect(fill = \"white\", color = NA),\n    panel.grid.major = element_line(color = \"grey85\", linewidth = 0.4),\n    panel.grid.minor = element_line(color = \"grey92\", linewidth = 0.3),\n    text = element_text(size = 14, family = \"Montserrat Medium\")\n  )\n\nggplotly(p3) |&gt; \n  layout(\n    legend = list(\n      x = 1.05,\n      y = 0.5,\n      xanchor = \"left\",\n      yanchor = \"middle\",\n      title = list(\n        text = \"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Год\"\n      )\n    )\n  )\n\n\n\n\n\nЗдесь мы видим, что статистически длиннее статьи были в 2024 году. Выбросы в обе стороны также ярко выражены именно в этом году. Могу предложить, что в 2025 году были введены требования оформления статей, которые регламентируют даже длину статьи.\nТеперь перейдите на вкладу NLP-анализ, чтобы продолжить изучать мое исследование!"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Crosstech Solutions Group",
    "section": "Сноски",
    "text": "Сноски\n\n\nРаспознавание лиц на микрокомпьютерах↩︎\nСекреты успешного собеседования: как получить оффер технарю↩︎\nКак выжить на первом испытательном сроке в IT и не только↩︎\nКак тимлиду проводить собеседование так, чтобы кандидат и компания получили от него максимум↩︎\nКак создать решение в области контейнерной безопасности: подводные камни, проблемы и их решение↩︎\nКогда лучше всего публиковать статьи в блог (Статистика из США и России)↩︎"
  }
]